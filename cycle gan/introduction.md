# Cycle Gan 简介

## 介绍

循环生成对抗网络（简称`CycleGans`）是一种深度学些算法，能够将**信息从一种表示形式转化成另一种表现形式**，例如可以将给定图片转化成不同风格，也可将图片背景模糊，信息的表现形式取决于所给训练集的表现形式。

`Cycle Gan `由两个生成式对抗网络（`Gan`）组成，直观来讲`Gan`是一种能够生成目标分布新数据的算法，例如给定一组人脸图像，该算法可以自学人脸的外观，生成新的人脸。而`Cycle Gan`则可以看做是是`Gan`的一种变体，因为前者并不是仅仅依据学到的单个分布来生成数据，而是通过另一个输入样本的分布来指导生成。换句话说，他学会了**从两个数据源转换数据**，开发人员提供了猫和狗的图片的情况下，可以实现二者的相互转化。



## 原理浅析

上文中提到，`Cycle Gan`可以简单的认为是由两个函数，分别负责两种不同风格的数据转换，其中之一是 $G(x) $，它将给定样本$x \in X$，转换成域为$Y$的元素；第二个是$F(y)$，它将元素$y \in Y$转化为域$X$的元素。
$$
G: X \rightarrow Y \\
F: Y \rightarrow X	\\
$$
 具体而言，为了学习$F$和$G$，使用了两个传统的`Gan`，每个`Gan`内部都有一个生成器网络，该网络负责如何根据需要转换数据。`Gan`的第一个生成器学习计算`F`，第二个生成器学习计算`G`， 即：
$$
G: Generates\ \hat{y} \ from \ samples \ x \\
F: Gemerates\ \hat{x} \ from \ samples \ y
$$




此外每个生成器都与一个鉴别器相关联，该鉴别器学习将**实际数据**与对应的**生成数据**分开，即：
$$
D_x: Discriminates \ y \ from \ G(x) \\
D_y: Discriminates \ x \ from \ F(y)
$$
因此，`Cycle Gan` 由两个生成器和鉴别器组成，他们学习变换函数`F`和`G`，此结构显示在下图中：

![img](https://pic2.zhimg.com/80/v2-705a5322f34e4cbebc0050714db42941_720w.webp)

每个`Gan`生成器通过最小化损失来学习对应的变换函数（`F`或`G`），通过计算生成数据与目标数据的差异来计算损失（可以将这部分理解为**重构损失**)，差异越大损失值越大。对于鉴别器而言，主要用来区分真实数据和合成数据。将生成器和鉴别器损失组合在一起，二者相互促进，彼此改善（这也是“对抗”的由来），训练器来欺骗鉴别器，并且鉴别器将被训练为从合成数据中更好的区分真实数据。最终结果是，生成器将非常擅长创建/转换所需数据（学习所需转换，如`F`和`G`）。总体而言，`Gan`的损失看起来像：
$$
Loss_{Gan}(G,D_y) = E_{y \sim \mathcal{p}_{data}(y)}[log(D_y(y))] \ + \ E_{x \sim \mathcal{p}_{data}(x)}[log( 1 - D_y(G_x(x)))]
$$
第一项表示`Discriminator loss`第二项表示`Generator loss`， **损失貌似将$y$和$G_x(x)$朝着相反的方向训练，如何保证$G_x(x)$生成的数据在域$Y$中呢？以及如何体现信息的不同域之间的转换呢？**`Cycle Gan`尝试最大化两个`Gan`损失的综合，以变换`F`和`G`。

>$Loss_{Gan}$损失主要用于训练鉴别器很好地区分原始数据和生成器生成的数据，他们并不关心生成器是否生成了目标域中的数据，约束生成器表现的是下一节要详细讲的`循环变换一致性`损失。
>

## 循环变换一致性

理想情况下，希望`Cycle Gan`学习一个周期一致的换函数`F`和`G`，这意味着在给定输入`x`的情况下，变换前后$F(G(x)) = \hat{x}$准确地输出原始输入$x$。从理论上讲着应该是可能的，因为在输入`x`上应用`G`将其映射到相应的域`Y`中，反之亦然。

周期一致性减少了网络学习到的**映射可能的集合**，并强迫使`F`和`G`进行相反的转换，**确保不会生成与两种目标都没有关系的数据（随意组合很容易产生）**，从而**简化模型的训练**。

> 想象一下，学习的函数$F$通过修改猫的耳朵将猫图片转换为狗图片，而$G$通过修改猫的鼻子将猫图片转换为猫图片。 尽管这些转换可以实现目标，但它们并不一致，因为它们对数据应用了不同的更改。 使用周期一致性迫使$F$和$G$彼此相反。 这样，通过修改猫的耳朵将猫图片转换为狗图片，通过以相反的方式将猫耳朵修改为猫图片。 如果这两个函数是周期一致的，则它们也是更有意义的映射。

![img](https://pic3.zhimg.com/80/v2-5424d11d221ace92f83e35276b1d5d16_720w.webp)

左：输入$x$循环一致性的表现，右输入$y$循环一致性的表现。

仅使用`Gan`损失训练`Cycle Gan`并不能保证循环的一致性。因此，需要额外的循环一致性损失来进行限制。直观来讲，很容易将该损失定义为输入值与对应前向预测函数之间的差异。差异越大，预测与原始输入的距离就越远。理想情况下，我们的网络将这种损失降到最低：
$$
Loss_{Cycle}= E_{x \sim \mathcal{p}_{data}(x)}[||G(F(x)) - x||_1] + E_{y \sim \mathcal{p}_{data}(y)}[||G(F(y)) - y||_1]
$$

循环一致性损失的引入十分巧妙，有如下三方面作用：

- 确保各个生成器能够朝着目标域生成数据，即不会瞎翻译一通，这也就回答了上一节中的问题。
- 能够确保翻译前后的对应一致性，对于图片风格转化而言也就是图片主体对应的内容不变，即实现pix2pix的转化功能
- 能够有效避免**模式坍塌**，即生成器不会把所有输入都映射到同一个输出上。

## 完整损失

用于训练网络的完整`CycleGan`损失的函数定义为两个`Gan`损失和`Cycle`一致性损失之和。

加权因子$ƛ$用于控制循环一致性损失在全部损失中的权重。 权重越高，与其他损失相比，减少循环一致性损失就越有意义。
$$
Loss_{full} = Loss_{Gan}(G, D_x) + Loss_{Gan}(F, D_y) + \lambda Loss_{cycle}
$$
经过优化以最小化此功能的CycleGAN将能够学习所需的变换$F$和$G$。



## 结果

`CycleGans`已经完成了多项任务的测试，并且能够成功解决它们。 这些任务的一些示例是：

### 图像转换

![img](https://pic4.zhimg.com/80/v2-f2602b1b838ba30c996ddfea3719caef_720w.webp)

输入：原始的花卉图片。输出：改进的花卉图片，并具有焦点和效果。

### 样式风格转换

![img](https://pic3.zhimg.com/80/v2-1e3a54adf7071ef26ccd7c9deb9eecde_720w.webp)

输入：风景图片。 输出：将相同的风景替换到不同的艺术风格下。

此外还有图像季节转换、音频转换等应用。

## Cycle GAN的问题

尽管CycleGAN在许多上述任务中都取得了明显的成功，但未显示出100％的成功率，甚至在有些场景下的转换是不恰当的：

![img](https://pic2.zhimg.com/80/v2-97e496f1c44abd039bd320b68a087d71_720w.webp)

用来变换马匹和斑马图像的CycleGan并未提供人类的输入，因此它可以生成任意变换。

进一步的研究可能集中在改进这些领域的工作。 一些策略包括使用更广泛和更多样化的数据集，以及使用**半监督学习**方法。

cyclegan 存在具体有如下几方面的问题：

- **模式崩溃**：生成器产生非常相似或者重复的输出，而不是丰富多样的结果，一般意味着转化的图像缺乏多样性。
- **细节丢失**：在处理细节（如细小纹理或者边缘）时可能会丢失信息，导致生成的图像在细节上不够精确或者略显模糊。
- **对齐问题**：cyclegan不要求成对出现的训练数据，这虽然是一个优势，但可能出现对应物体不合理变换的问题，这就意味着在处理精确的对齐任务（上文提到的斑马转换和面部特征转换）时可能不够准确。



## 最后

下一节将探讨Cycle代码及其不足以及改进方式。









