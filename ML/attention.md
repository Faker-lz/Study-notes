# Attention learning
## trap
在 PyTorch 中，如果模型的参数或梯度出现 nan 值，那么在反向传播过程中，这些 nan 值会被传播并可能影响到其他参数的更新。

具体来说，如果损失函数计算结果为nan，那么在反向传播过程中，所有参数的梯度都将变为 nan。这是因为梯度是通过损失函数对参数的偏导数计算得到的，如果损失函数为 nan，那么其偏导数也将为 nan。

此外，如果模型的某个参数在更新过程中变为 nan，那么在下一次前向传播过程中，所有依赖于该参数的计算结果都将变为 nan，从而导致损失函数值为 nan，进而影响到反向传播过程。

因此，如果在训练过程中出现 nan 值，需要及时处理，例如通过调整学习率、添加梯度裁剪、使用更稳定的优化器等方法来避免 nan 值的产生。同时，也可以通过打印和监控模型参数和梯度，来帮助定位和解决出现 nan 值的问题。